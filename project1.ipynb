{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-18T03:52:29.738353Z","iopub.execute_input":"2024-05-18T03:52:29.738678Z","iopub.status.idle":"2024-05-18T03:52:30.787733Z","shell.execute_reply.started":"2024-05-18T03:52:29.738650Z","shell.execute_reply":"2024-05-18T03:52:30.786784Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\ncls = pipeline(\"sentiment-analysis\")\ncls(\"I hate you\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T03:56:47.763439Z","iopub.execute_input":"2024-05-18T03:56:47.764056Z","iopub.status.idle":"2024-05-18T03:57:10.636385Z","shell.execute_reply.started":"2024-05-18T03:56:47.764028Z","shell.execute_reply":"2024-05-18T03:57:10.635375Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-18 03:56:55.845511: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-18 03:56:55.845608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-18 03:56:56.009255: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nNo model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07642eb90342427ab2b5ceb0a0749af7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbaa29fb1e31490286ab42291bf24b88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec71399ae26045188d1e1c9674ce17b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27bfcc41bd5946e086f99c1a4e8b0267"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[{'label': 'NEGATIVE', 'score': 0.9991129040718079}]"},"metadata":{}}]},{"cell_type":"code","source":"clf = pipeline(\"zero-shot-classification\")\nclf(\"this course is al about transformer libarary\", candidate_labels=[\"education\", \"politics\", \"business\"],)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T04:47:23.086596Z","iopub.execute_input":"2024-05-18T04:47:23.087148Z","iopub.status.idle":"2024-05-18T04:47:25.784105Z","shell.execute_reply.started":"2024-05-18T04:47:23.087118Z","shell.execute_reply":"2024-05-18T04:47:25.783141Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'sequence': 'this course is al about transformer libarary',\n 'labels': ['education', 'business', 'politics'],\n 'scores': [0.5160566568374634, 0.2789328396320343, 0.2050105184316635]}"},"metadata":{}}]},{"cell_type":"code","source":"genrate = pipeline(\"text-generation\")\ngenrate(\"I am\", max_length=50, num_return_sequences=5)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T04:48:35.923749Z","iopub.execute_input":"2024-05-18T04:48:35.924681Z","iopub.status.idle":"2024-05-18T04:48:43.838368Z","shell.execute_reply.started":"2024-05-18T04:48:35.924650Z","shell.execute_reply":"2024-05-18T04:48:43.837473Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa5d01423d3845378d20bcda345a75c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a22400c66245f29f9b2d8501ef17a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf1e56541cbc4d7b9f04fe74920254a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a56f4bf5ca4e5981d04bf71659d38d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f990c581c0e4ab98987862b579c0377"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3ef2ec3762740758cfb99fd7b9b0f31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7933e3ccbff4a199b2069d7b8819a36"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'I am the first and I am not in charge of all her stuff, or any of my own and never would have done otherwise\".\\n\\n\"Yes, but sometimes for such an innocent man, being told what all that stuff is about, what'},\n {'generated_text': 'I am confident that you will enjoy this project as much as I do! I am sure that once I have all of the resources I can get to you, I will share the best design of this project with everyone who has made it.\\n\\n\\n'},\n {'generated_text': 'I am only going as far as possible. I know the details.\" \"I would love to, but I also want to keep you informed of that progress for the record, what I do, when.\" Her brother looked at him. He didn\\'t'},\n {'generated_text': \"I am trying very hard to get my child up into the right age and I am trying to make a living helping my kids develop. I think it's a very difficult job in our society and I think these days we should support anybody trying to do\"},\n {'generated_text': 'I am not sure how much more you expect your own employees would be, but some workers would expect the same, if not more, pay. It is obvious that employers value their employees, especially young and newly hired workers who are often underperforming.'}]"},"metadata":{}}]},{"cell_type":"code","source":"genrate = pipeline(\"text-generation\", model=\"distilgpt2\")\ngenrate(\"I am\", max_length=50, num_return_sequences=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T04:54:28.431852Z","iopub.execute_input":"2024-05-18T04:54:28.432236Z","iopub.status.idle":"2024-05-18T04:54:34.303092Z","shell.execute_reply.started":"2024-05-18T04:54:28.432207Z","shell.execute_reply":"2024-05-18T04:54:34.302179Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de92ab022acb4469b52d77cfd8811fc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04251d355a034066b04a48478972440a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f24203ebb6c4620bc76d1d101256a22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5868b51941af4f0e8d68e1fc8004c042"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a24c08f9e1e743f68f1467710218c387"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a715062f681549c5bd3d25692ef9b7f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed67b021590d475cae15904a91c0ba54"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"I am being treated for the disease, I am now a bit of a big fan of this idea, but it's the ones that I think is more important than what it seems like, so we hope to see some work out in the long run\"},\n {'generated_text': 'I am here to help you. You are not a bad person. If I would be happy if I met you and let me know if I could help you. I am not perfect. Please tell me why you are so much better than me,'},\n {'generated_text': 'I am still here and here and I am still here. But we’re trying to get the good guys to make her happy.\\nSo, you can see me moving out, and that all is over. But now I was too busy'},\n {'generated_text': 'I am sorry. You are not allowed to access this website unless otherwise specified or required by the law. Please complete the form and give your name.'},\n {'generated_text': 'I am going to write about the game to your children, and the game is an awful series of games. I will be writing this chapter about why I decided that I would like to write to your children, and the game is an awful series of'}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}